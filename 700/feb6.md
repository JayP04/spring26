# implementation of DQN and DDQN

### Cartpole
- use full dimenational vector to indicate.
- we have two actions only left and right so 0 and 1.
- reward is 1 for every step, so the agent will try to keep the pole up
- we have state, action, reward
